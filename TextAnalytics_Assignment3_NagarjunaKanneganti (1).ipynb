{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel, LsiModel, LdaModel,CoherenceModel\n",
    "from textblob import TextBlob\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data file using pandas\n",
    "df = pd.read_csv(\"BBC-articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "#initializing lemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the text by removing the punctuation at ends of the string, making it lower, \n",
    "#removing whitespace characters and extra spaces\n",
    "#clean method specifies which method to use for cleaning.\n",
    "def clean_text(text,clean_method):\n",
    "    text = text.strip(punctuation).lower()\n",
    "    text = re.sub(r'[^a-zA-Z]',' ',text)\n",
    "    text = re.sub(r' +',' ',text)\n",
    "    #tokenizing using the nltk tokenize for generating words in an article\n",
    "    words = nltk.tokenize.word_tokenize(text)\n",
    "    words = [w for w in words if w not in stop_words and len(w)>2]\n",
    "    if(clean_method == 1):\n",
    "        #initializing the lemmatizer\n",
    "        lemma = nltk.stem.WordNetLemmatizer()\n",
    "        lemmatized = [lemma.lemmatize(w) for w in words]\n",
    "        return lemmatized\n",
    "    elif(clean_method == 2):\n",
    "        #joining back to a string to extract nouns using textblob methods\n",
    "        modified_text=' '.join([w for w in words])\n",
    "        blob_object = TextBlob(modified_text)\n",
    "        #Limiting the word list with nouns\n",
    "        word_list_nouns = [word for word,pos in blob_object.tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "        return word_list_nouns\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining optimum number of topics using coherence values \n",
    "def maxCoherence(model,corpus,dict_1,token_1):\n",
    "    coherence_values = []\n",
    "    min_topics, max_topics, step = 1, 5, 1\n",
    "    for i in range(min_topics, max_topics, step):\n",
    "        m = model(corpus,id2word = dict_1,num_topics = i)       \n",
    "        coherencemodel = CoherenceModel(model=m,texts = token_1, dictionary=dict_1, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return coherence_values.index(max(coherence_values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to build model based on the parameters\n",
    "def model(model,corpus,dict_1,num_topics):\n",
    "    return model(corpus,id2word = dict_1, num_topics = num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_preparation(method,clean_method):\n",
    "    #method is to prepare td-idf according to 1 and 2 questions and clean method is to prepare according to 3rd question\n",
    "    #cleaning the text and creating a new list to store it\n",
    "    #method is used to solved 3 questions at once by passing parameters\n",
    "    token = []\n",
    "    for i in range(0,len(df)):\n",
    "        token.append(clean_text(df['text'][i],clean_method))\n",
    "    #creating a dictionary from tokens\n",
    "    if(method == 1):\n",
    "        dict_1 = Dictionary(token)\n",
    "        #creating document term matrix using doc2bow method from dictionary\n",
    "        dtm = [dict_1.doc2bow(doc) for doc in token]\n",
    "        # TF-IDF Vectorization\n",
    "        tfidf = TfidfModel(dtm)\n",
    "        tfidf = tfidf[dtm]\n",
    "        dict1 = dict_1\n",
    "        return tfidf,dict1,token\n",
    "    elif(method == 2):\n",
    "        dict_1 = Dictionary(token)\n",
    "        dict_1.filter_extremes(no_below=5, no_above=0.90) # filtering the top10% and words less than 5 times in docs\n",
    "        dtm = [dict_1.doc2bow(doc) for doc in token]\n",
    "        tfidf = TfidfModel(dtm) #tf-idf vectorization\n",
    "        tfidf = tfidf[dtm]\n",
    "        dict1 = dict_1\n",
    "        return tfidf,dict1,token\n",
    "    elif(method == 3):\n",
    "        dict_1 = Dictionary(token)\n",
    "        #creating document term matrix using doc2bow method from dictionary\n",
    "        dtm = [dict_1.doc2bow(doc) for doc in token]\n",
    "        # TF-IDF Vectorization\n",
    "        tfidf = TfidfModel(dtm)\n",
    "        tfidf = tfidf[dtm]\n",
    "        dict1 = dict_1\n",
    "        return tfidf,dict1,token\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dominant topic and corresponding keywords for each article\n",
    "def keywords_generation(model,tfidf):\n",
    "    keywords_df = pd.DataFrame()   \n",
    "    for i, row in enumerate(model[tfidf]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the central topic and Keywords for each article\n",
    "        for j, (topic_num, topic) in enumerate(row):\n",
    "            if j == 0:  # row is sorted so every first element in the list is the dominant keyword\n",
    "                keywords = model.show_topic(topic_num, topn = 5) # top 5 keywords\n",
    "                words = ' '.join([w for w,p in keywords])\n",
    "                keywords_df = keywords_df.append(pd.Series([words]), ignore_index=True)\n",
    " \n",
    "    return keywords_df\n",
    "         \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating coherence\n",
    "lsi_coherence1 = maxCoherence(LsiModel,tfidf_preparation(1,1)[0],tfidf_preparation(1,1)[1],tfidf_preparation(1,1)[2])\n",
    "lda_coherence2 = maxCoherence(LdaModel,tfidf_preparation(1,1)[0],tfidf_preparation(1,1)[1],tfidf_preparation(1,1)[2])\n",
    "lsi_coherence3 = maxCoherence(LsiModel,tfidf_preparation(2,1)[0],tfidf_preparation(2,1)[1],tfidf_preparation(2,1)[2])\n",
    "lda_coherence4 = maxCoherence(LdaModel,tfidf_preparation(2,1)[0],tfidf_preparation(2,1)[1],tfidf_preparation(2,1)[2])\n",
    "lsi_coherence5 = maxCoherence(LsiModel,tfidf_preparation(3,2)[0],tfidf_preparation(3,2)[1],tfidf_preparation(3,2)[2])\n",
    "lda_coherence6 = maxCoherence(LdaModel,tfidf_preparation(3,2)[0],tfidf_preparation(3,2)[1],tfidf_preparation(3,2)[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal number of topics for BBC articles are 3 3 1 2 1 3\n"
     ]
    }
   ],
   "source": [
    "print(\"optimal number of topics for BBC articles are\", lsi_coherence1,lda_coherence2,lsi_coherence3,lda_coherence4,lsi_coherence5,lda_coherence6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building models\n",
    "lsi_model1 = model(LsiModel,tfidf_preparation(1,1)[0],tfidf_preparation(1,1)[1],lsi_coherence1)\n",
    "lda_model2 = model(LdaModel,tfidf_preparation(1,1)[0],tfidf_preparation(1,1)[1],lda_coherence2)\n",
    "lsi_model3 = model(LsiModel,tfidf_preparation(2,1)[0],tfidf_preparation(2,1)[1],lsi_coherence3)\n",
    "lda_model4 = model(LdaModel,tfidf_preparation(2,1)[0],tfidf_preparation(2,1)[1],lda_coherence4)\n",
    "lsi_model5 = model(LsiModel,tfidf_preparation(3,2)[0],tfidf_preparation(3,2)[1],lsi_coherence5)\n",
    "lda_model6 = model(LdaModel,tfidf_preparation(3,2)[0],tfidf_preparation(3,2)[1],lda_coherence6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  after normal cleaning of the text corpus (punctuation removal, stopword removal, etc.),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LSI_keywords1'] = keywords_generation(lsi_model1,tfidf_preparation(1,1)[0])\n",
    "df['LDA_keywords1'] = keywords_generation(lda_model2,tfidf_preparation(1,1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. with term frequency filter, to exclude the top 10% of the most frequent words and words that appear less than 5 times in the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LSI_keywords2'] = keywords_generation(lsi_model3,tfidf_preparation(2,1)[0])\n",
    "df['LDA_keywords2'] = keywords_generation(lda_model4,tfidf_preparation(2,1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. with a part of speech filter, to limit your TD-IDF matrix to nouns only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LSI_keywords3'] = keywords_generation(lsi_model5,tfidf_preparation(3,2)[0])\n",
    "df['LDA_keywords3'] = keywords_generation(lda_model6,tfidf_preparation(3,2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>LSI_keywords1</th>\n",
       "      <th>LDA_keywords1</th>\n",
       "      <th>LSI_keywords2</th>\n",
       "      <th>LDA_keywords2</th>\n",
       "      <th>LSI_keywords3</th>\n",
       "      <th>LDA_keywords3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>labour election blair tax game</td>\n",
       "      <td>mobile phone film search game</td>\n",
       "      <td>labour election game film blair</td>\n",
       "      <td>mobile phone sale market profit</td>\n",
       "      <td>election blair government party people</td>\n",
       "      <td>data phones bank phone virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>labour election blair tax game</td>\n",
       "      <td>mobile phone film search game</td>\n",
       "      <td>labour election game film blair</td>\n",
       "      <td>film blair election award search</td>\n",
       "      <td>election blair government party people</td>\n",
       "      <td>data phones bank phone virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "      <td>labour election blair tax game</td>\n",
       "      <td>mobile phone film search game</td>\n",
       "      <td>labour election game film blair</td>\n",
       "      <td>film blair election award search</td>\n",
       "      <td>election blair government party people</td>\n",
       "      <td>film sales awards oil dollar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "      <td>labour election blair tax game</td>\n",
       "      <td>party blair election kilroy tax</td>\n",
       "      <td>labour election game film blair</td>\n",
       "      <td>mobile phone sale market profit</td>\n",
       "      <td>election blair government party people</td>\n",
       "      <td>data phones bank phone virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "      <td>labour election blair tax game</td>\n",
       "      <td>mobile phone film search game</td>\n",
       "      <td>labour election game film blair</td>\n",
       "      <td>film blair election award search</td>\n",
       "      <td>election blair government party people</td>\n",
       "      <td>film sales awards oil dollar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  \\\n",
       "0           tech  tv future in the hands of viewers with home th...   \n",
       "1       business  worldcom boss  left books alone  former worldc...   \n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
       "3          sport  yeading face newcastle in fa cup premiership s...   \n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
       "\n",
       "                    LSI_keywords1                    LDA_keywords1  \\\n",
       "0  labour election blair tax game    mobile phone film search game   \n",
       "1  labour election blair tax game    mobile phone film search game   \n",
       "2  labour election blair tax game    mobile phone film search game   \n",
       "3  labour election blair tax game  party blair election kilroy tax   \n",
       "4  labour election blair tax game    mobile phone film search game   \n",
       "\n",
       "                     LSI_keywords2                     LDA_keywords2  \\\n",
       "0  labour election game film blair   mobile phone sale market profit   \n",
       "1  labour election game film blair  film blair election award search   \n",
       "2  labour election game film blair  film blair election award search   \n",
       "3  labour election game film blair   mobile phone sale market profit   \n",
       "4  labour election game film blair  film blair election award search   \n",
       "\n",
       "                            LSI_keywords3                 LDA_keywords3  \n",
       "0  election blair government party people  data phones bank phone virus  \n",
       "1  election blair government party people  data phones bank phone virus  \n",
       "2  election blair government party people  film sales awards oil dollar  \n",
       "3  election blair government party people  data phones bank phone virus  \n",
       "4  election blair government party people  film sales awards oil dollar  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding most common keywords among all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keyword'] = df[df.columns[2:]].apply(lambda x: ' '.join(x.dropna().astype(str)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting 5 most common keywords from all the LSI and LDA Keywords\n",
    "top_5_words = []\n",
    "for i in df.index:\n",
    "    common_keywords = df['keyword'][i].split(' ')\n",
    "    most_occur = Counter(common_keywords).most_common(5) \n",
    "    top_5_words = ' '.join([word[0] for word in most_occur])\n",
    "\n",
    "df['common_5_words'] = top_5_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>LSI_keywords1</th>\n",
       "      <th>LDA_keywords1</th>\n",
       "      <th>LSI_keywords2</th>\n",
       "      <th>LDA_keywords2</th>\n",
       "      <th>LSI_keywords3</th>\n",
       "      <th>LDA_keywords3</th>\n",
       "      <th>keyword</th>\n",
       "      <th>common_5_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "      <td>labour election blair tax game</td>\n",
       "      <td>mobile phone film search game</td>\n",
       "      <td>labour election game film blair</td>\n",
       "      <td>mobile phone sale market profit</td>\n",
       "      <td>election blair government party people</td>\n",
       "      <td>data phones bank phone virus</td>\n",
       "      <td>labour election blair tax game mobile phone fi...</td>\n",
       "      <td>election blair film game party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "      <td>labour election blair tax game</td>\n",
       "      <td>mobile phone film search game</td>\n",
       "      <td>labour election game film blair</td>\n",
       "      <td>film blair election award search</td>\n",
       "      <td>election blair government party people</td>\n",
       "      <td>data phones bank phone virus</td>\n",
       "      <td>labour election blair tax game mobile phone fi...</td>\n",
       "      <td>election blair film game party</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text  \\\n",
       "0      tech  tv future in the hands of viewers with home th...   \n",
       "1  business  worldcom boss  left books alone  former worldc...   \n",
       "\n",
       "                    LSI_keywords1                  LDA_keywords1  \\\n",
       "0  labour election blair tax game  mobile phone film search game   \n",
       "1  labour election blair tax game  mobile phone film search game   \n",
       "\n",
       "                     LSI_keywords2                     LDA_keywords2  \\\n",
       "0  labour election game film blair   mobile phone sale market profit   \n",
       "1  labour election game film blair  film blair election award search   \n",
       "\n",
       "                            LSI_keywords3                 LDA_keywords3  \\\n",
       "0  election blair government party people  data phones bank phone virus   \n",
       "1  election blair government party people  data phones bank phone virus   \n",
       "\n",
       "                                             keyword  \\\n",
       "0  labour election blair tax game mobile phone fi...   \n",
       "1  labour election blair tax game mobile phone fi...   \n",
       "\n",
       "                   common_5_words  \n",
       "0  election blair film game party  \n",
       "1  election blair film game party  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_bbc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From the above methods, LDA_keywords3(which is parts of speech filter(only nouns)) seems the best among all the methods because the words are data,phones,phone and virus. 4 out of the 5 keywords are related to tech category"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
